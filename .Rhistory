## Map to z(beta) variables:
## Update z values (does accept/reject with slice sampler):
z[iter, ] <- update_z(z[iter - 1, ], z_1m[iter - 1, ], J, n_i = n_i
, K, g[iter], prior.alpha)
psi[iter, ] <- pbeta(exp(z[iter, ]), .5, .5)
z_1m[iter, ] <- sapply(z[iter, ], log1mexp)
alpha[iter, ] <- alpha_map(z[iter, ], z_1m[iter, ])
for (k in 1:K) {
theta[iter, k, !is.na(n_i[k, subset])] <- LaplacesDemon::rdirichlet(1, exp(g[iter] + alpha[iter, subset]) + n_i[k, subset][!is.na(n_i[k, subset])])
}
}
# Save row draws:
alpha_draws <- array(0, dim = c(B, length(n_i[k, ])))
alpha_draws[, !is.na(n_i[1, ])] <- exp(alpha[-c(1:500), subset])
gamma_draws <- exp(g[-c(1:500)])
theta_draws <- theta[-c(1:500), , ]
#print(i)
return(list(
alpha = alpha_draws,
gamma = gamma_draws,
theta = theta_draws
))
}
#' HAMC-EPA model
#'
#' @description
#' This function fits an indpendent HAMC-EPA model on each row of the transition matrix and outputs posterior draws of clustering, alpha, gamma, and the transition probabilities.
#'
#'
#' @param N A three dimensional array of counts (KxIxJ) where K is the number of subgroups, I is the number of transitory states, J is the total number of states. Include NA's in matrix for impossible transitions.
#' @param method The MCMC approach to obtaining posterior draws of the random clusters. Options "aao" or "seq". "aao" is an "all-at-once" approach in that it evaluates the posterior probability of each possible partition. "seq" does a sequential allocation of clustering given the previous clustering draw. When there are a small number of subgroups "aao" may be prefered however as the number of subgroups increases the computation time increases dramatically.
#' @param B Number of desired posterior estimates
#' @param thin Thinning of MCMC draws, i.e. thin = 5, means every 5th draw will be returned.
#' @param prior.alpha The value to be included in the prior for the Dirichlet on alpha, will be uniform. Default is 1/(# of possible transition for each row).
#' @param g.a The prior shape parameter of the gamma distribution for the gamma parameter. Default uses a mean of 20 and standard deviation of 18.
#' @param g.b The prior rate parameter of the gamma distribution for the gamma parameter. Default uses a mean of 20 and standard deviation of 18.
#' @param dist A KxK symmetric matrix that includes the prior information on the distance between subgroups. Defaults to each group is sequentially one from the next in line.
#' @param MCMC.cores The number of cores desired to use to run, if greater than 1 parallel processing will be used. Default is 1 (no parallelization).
#' @param burnin The number of burn in iterations to be removed from the posterior draws. Default is 500.
#'
#' @return A list with the following:
#'  \itemize{
#'    \item groups - The posterior draws of the clustering from each MCMC draw. (BxIxK)
#'    \item alpha - Posterior draws of the alpha parameter. (BxIxJ)
#'    \item gamma - Posterior draws of the gamma parameter. (BxI)
#'    \item theta - Posterior draws of the transition probabilities. (BxKxIxJ)
#'  }
#' @export
#' @examples
#'
# Write function:
epa_hamc <- function(N,
method = "aao",
B = 10000,
thin = 1,
prior.alpha = NULL,
g.a = NULL,
g.b = NULL,
dist = NULL,
MCMC.cores = 1,
burnin = 500) {
# Check compatability of N:
if (!is.array(N)) {
stop(paste("N must be an array."))
}
if (length(dim(N)) < 3) {
stop(paste("N must be a three dimensional array."))
}
# Check method argument:
if (!(method %in% c("aao", "seq"))) {
stop(paste("Invalid method argument"))
}
# Check B, thin, prior.alpha, g.a, g.b are numeric if input is supplied:
if (!is.numeric(B)) {
stop(paste("B must be numeric"))
}
if (!is.numeric(thin)) {
stop(paste("thin must be numeric"))
}
if (!is.null(g.a) & !is.numeric(g.a)) {
stop(paste("g.a must be numeric"))
}
if (!is.null(g.b) & !is.numeric(g.b)) {
stop(paste("g.b must be numeric"))
}
# Make sure prior parameters are positive:
if (!is.null(prior.alpha)) {
if (prior.alpha <= 0) {
stop(paste("prior.alpha must be positive"))
}
}
if (is.null(prior.alpha)) {
prior.alpha <- c()
for (i in 1:dim(N)[2]) {
prior.alpha[i] <- 1 / sum(!is.na(N[1, i, ]))
}
}
if (!is.null(g.a)) {
if (g.a <= 0) {
stop(paste("g.a must be positive"))
}
}
if (!is.null(g.b)) {
if (g.b <= 0) {
stop(paste("g.b must be positive"))
}
}
# Check distance matrix and correct dimensions:
K <- dim(N)[1]
if (!is.null(dist)) {
if (!is.matrix(dist)) {
stop("dist must be a matrix.")
}
if (dim(dist)[1] != K) {
stop("Wrong dimensions for distance matrix.")
}
}
# Check if method and number of groups match:
if(K > 13 & method == "aao"){
stop("K is greater than 13 and method must be sequential.")
}
# Check dimensions
if (is.null(dist)) {
dist <- matrix(1, nrow = K, ncol = K)
for (k in 1:K) {
dist[c(1:K)[-k], k] <- abs(c(1:K)[-k] - k)
}
dist[K, K] <- 1
# Convert to similarity matrix for EPA model:
dist <- dist ^ (-.5)
} else {
# Convert to similarity matrix for EPA model:
dist <- dist ^ (-.5)
}
## Populate g.a and g.b if missing:
if (is.null(g.a) | is.null(g.b)) {
mu <- 20
sd <- 18
g.b <- mu / sd ^ 2
g.a <- mu * g.b
}
# Make the data into a list:
count.list <- list()
for (i in 1:dim(N)[2]) {
count.list[[i]] <- N[, i, ]
}
## Fit model:
## Check configuration of prior.alpha if it varies from row to row:
if (length(unique(prior.alpha)) == 1) {
prior.alpha <- unique(prior.alpha)
fit <- parallel::mclapply(count.list,
\(x) epa_mcmc(x, B + burnin, thin, method, prior.alpha, g.a, g.b, dist),
mc.cores = MCMC.cores)
} else{
for (i in 1:dim(N)[2]) {
count.list[[i]] <- cbind(count.list[[i]], prior.alpha[i])
}
fit <- parallel::mclapply(count.list,
\(x) epa_mcmc(x[, 1:(ncol(x) - 1)], B + burnin, thin, method, x[1, ncol(x)], g.a, g.b, dist),
mc.cores = MCMC.cores)
}
## Create output list options:
I <- dim(N)[2]
J <- dim(N)[3]
groupings <- array(NA, dim = c(B, I, K))
alpha <- array(0, dim = c(B, I, J))
gamma <- array(0, dim = c(B, I))
theta <- array(0, dim = c(B, K, I, J))
for (i in 1:I) {
groupings[, i, ] <- fit[[i]][[1]][-c(1:burnin), ]
alpha[, i, ] <- fit[[i]][[2]][-c(1:burnin), ]
gamma[, i] <- fit[[i]][[3]][-c(1:burnin)]
theta[, , i, ] <- fit[[i]][[4]][-c(1:burnin), , ]
}
output <- list(
groups = groupings,
alpha = alpha,
gamma = gamma,
theta = theta
)
return(output)
}
t1 <- count.dat[,1,,drop = F]
test1 <- epa_hamc(t1, thing = 5)
test1 <- epa_hamc(t1, thin = 5)
method = "aao"
B = 10000
thin = 1
prior.alpha = NULL
g.a = NULL
g.b = NULL
dist = NULL
MCMC.cores = 1
burnin = 500
# Check compatability of N:
if (!is.array(N)) {
stop(paste("N must be an array."))
}
if (length(dim(N)) < 3) {
stop(paste("N must be a three dimensional array."))
}
# Check method argument:
if (!(method %in% c("aao", "seq"))) {
stop(paste("Invalid method argument"))
}
# Check B, thin, prior.alpha, g.a, g.b are numeric if input is supplied:
if (!is.numeric(B)) {
stop(paste("B must be numeric"))
}
if (!is.numeric(thin)) {
stop(paste("thin must be numeric"))
}
if (!is.null(g.a) & !is.numeric(g.a)) {
stop(paste("g.a must be numeric"))
}
if (!is.null(g.b) & !is.numeric(g.b)) {
stop(paste("g.b must be numeric"))
}
# Make sure prior parameters are positive:
if (!is.null(prior.alpha)) {
if (prior.alpha <= 0) {
stop(paste("prior.alpha must be positive"))
}
}
if (is.null(prior.alpha)) {
prior.alpha <- c()
for (i in 1:dim(N)[2]) {
prior.alpha[i] <- 1 / sum(!is.na(N[1, i, ]))
}
}
if (!is.null(g.a)) {
if (g.a <= 0) {
stop(paste("g.a must be positive"))
}
}
if (!is.null(g.b)) {
if (g.b <= 0) {
stop(paste("g.b must be positive"))
}
}
prior.alpha = 1/15
t1
N_i <- t1
# Check distance matrix and correct dimensions:
K <- dim(N)[1]
if (!is.null(dist)) {
if (!is.matrix(dist)) {
stop("dist must be a matrix.")
}
if (dim(dist)[1] != K) {
stop("Wrong dimensions for distance matrix.")
}
}
# Check if method and number of groups match:
if(K > 13 & method == "aao"){
stop("K is greater than 13 and method must be sequential.")
}
K <- 5
# Check dimensions
if (is.null(dist)) {
dist <- matrix(1, nrow = K, ncol = K)
for (k in 1:K) {
dist[c(1:K)[-k], k] <- abs(c(1:K)[-k] - k)
}
dist[K, K] <- 1
# Convert to similarity matrix for EPA model:
dist <- dist ^ (-.5)
} else {
# Convert to similarity matrix for EPA model:
dist <- dist ^ (-.5)
}
## Populate g.a and g.b if missing:
if (is.null(g.a) | is.null(g.b)) {
mu <- 20
sd <- 18
g.b <- mu / sd ^ 2
g.a <- mu * g.b
}
# Fix n_i:
non.na.ind <- !is.na(N_i[1, ])
N_i
dim(N_i)
N_i <- count.dat[,1,]
# Fix n_i:
non.na.ind <- !is.na(N_i[1, ])
J <- sum(non.na.ind)#ifelse(is.null(ncol(N_i)), length(N_i), ncol(N_i))
n_i <- N_i[, !is.na(N_i[1, ])]
if (is.null(nrow(n_i))) {
n_i <- array(n_i, dim = c(1, length(n_i)))
}
K <- ifelse(is.null(nrow(n_i)), 1, nrow(n_i))
# Set prior parameters:
prior.alpha <- rep(prior.alpha, ncol(n_i))
beta <- beta_sav <- .9
delta <- delta_sav <- 0.01
sigma <- 1:K
k_rep <- floor(K / 2)
## Get initial values for alpha and gamma
alpha <- array(NA, dim = c(1, ncol(n_i)))
alpha[1, ] <- rep(1 / ncol(n_i), ncol(n_i))
z <- alpha_to_z(log(alpha))
z_1m <- sapply(z, log1mexp)
gamma <- gamma_sav <- 5#rgamma(1, g.a, g.b)
tables <- matrix(c(1, 1), nrow = 2)
group_alloc <- 1
groupings_sav <- array(NA, dim = c(B, nrow(n_i)))
alpha_sav <- array(NA, dim = c(B, ncol(n_i)))
theta_sav <- array(NA, dim = c(B, K, ncol(n_i)))
# Possible partitions:
if(K <= 13){
p <- salso::enumerate.partitions(K)
groupings <- p[sample(1:nrow(p), 1), ]
} else {
num_groups <- sample(1:K, 1)
groupings <- sample(1:num_groups, K, replace = TRUE)
}
# Reorder by counts:
max.col <- which.max(apply(n_i, 2, sum))
n_i <- n_i[ , c(c(1:length(n_i[1,]))[-max.col], max.col)]
if(max.col == 1){
subset <- c(length(alpha), max.col:(length(alpha) - 1))
} else if(max.col == length(alpha)){
subset <- 1:length(alpha)
}else{
subset <- c(1:(max.col - 1), length(alpha), max.col:(length(alpha) - 1))
}
# Run MCMC:
for (b in 2:(B * thin)) {
## Update groupings:
if (method == "aao") {
groupings <- update_groupings_aao(p,
beta,
delta,
dist,
sigma,
alpha,
gamma,
n_i,
prior.alpha,
g.a,
g.b,
K)
} else{
groupings <- update_groupings_seq(n_i,
groupings,
alpha,
gamma,
beta,
delta,
sigma,
dist,
prior.alpha,
g.a,
g.b,
K)
}
## Update permutation (sigma):
sigma <- update_sigma(sigma, k_rep, groupings, beta, delta, dist)
## Update mass parameter:
beta <- update_beta(beta, groupings, delta, dist, sigma)
## Update discount parameter (delta):
delta <- update_delta(groupings, beta, delta, dist, sigma)
# Update gamma/alpha:
# Combine counts
n_curr <- combine_counts(groupings, n_i)
# Update gamma:
gamma <- exp(gamma_update(z, z_1m, ncol(n_i), n_i = n_curr, nrow(n_curr) , log(gamma), g.a, g.b))
# Update z:
z <- update_z(z,
z_1m,
ncol(n_i),
n_i = n_curr,
nrow(n_curr),
log(gamma),
unique(prior.alpha))
z_1m <- sapply(z, log1mexp)
# Translate to alpha:
alpha <- exp(alpha_map(z, z_1m))
# Thin:
if (b %% thin == 0) {
alpha_sav[b / thin, ] <- alpha[subset]
groupings_sav[b / thin, ] <- groupings
gamma_sav[b / thin] <- gamma
beta_sav[b / thin] <- beta
delta_sav[b / thin] <- delta
for (g in unique(groupings)) {
ind <- which(groupings == g)
theta_sav[b / thin, ind, ] <- matrix(
rep(
LaplacesDemon::rdirichlet(1, n_curr[g, ] + alpha * gamma)[1, subset],
length(ind)
),
nrow = length(ind),
byrow = T
)
}
}
}
thin = 5
# Fix n_i:
non.na.ind <- !is.na(N_i[1, ])
J <- sum(non.na.ind)#ifelse(is.null(ncol(N_i)), length(N_i), ncol(N_i))
n_i <- N_i[, !is.na(N_i[1, ])]
if (is.null(nrow(n_i))) {
n_i <- array(n_i, dim = c(1, length(n_i)))
}
K <- ifelse(is.null(nrow(n_i)), 1, nrow(n_i))
beta <- beta_sav <- .9
delta <- delta_sav <- 0.01
sigma <- 1:K
k_rep <- floor(K / 2)
## Get initial values for alpha and gamma
alpha <- array(NA, dim = c(1, ncol(n_i)))
alpha[1, ] <- rep(1 / ncol(n_i), ncol(n_i))
z <- alpha_to_z(log(alpha))
z_1m <- sapply(z, log1mexp)
gamma <- gamma_sav <- 5#rgamma(1, g.a, g.b)
tables <- matrix(c(1, 1), nrow = 2)
group_alloc <- 1
groupings_sav <- array(NA, dim = c(B, nrow(n_i)))
alpha_sav <- array(NA, dim = c(B, ncol(n_i)))
theta_sav <- array(NA, dim = c(B, K, ncol(n_i)))
# Possible partitions:
if(K <= 13){
p <- salso::enumerate.partitions(K)
groupings <- p[sample(1:nrow(p), 1), ]
} else {
num_groups <- sample(1:K, 1)
groupings <- sample(1:num_groups, K, replace = TRUE)
}
# Reorder by counts:
max.col <- which.max(apply(n_i, 2, sum))
n_i <- n_i[ , c(c(1:length(n_i[1,]))[-max.col], max.col)]
if(max.col == 1){
subset <- c(length(alpha), max.col:(length(alpha) - 1))
} else if(max.col == length(alpha)){
subset <- 1:length(alpha)
}else{
subset <- c(1:(max.col - 1), length(alpha), max.col:(length(alpha) - 1))
}
# Run MCMC:
for (b in 2:(B * thin)) {
## Update groupings:
if (method == "aao") {
groupings <- update_groupings_aao(p,
beta,
delta,
dist,
sigma,
alpha,
gamma,
n_i,
prior.alpha,
g.a,
g.b,
K)
} else{
groupings <- update_groupings_seq(n_i,
groupings,
alpha,
gamma,
beta,
delta,
sigma,
dist,
prior.alpha,
g.a,
g.b,
K)
}
## Update permutation (sigma):
sigma <- update_sigma(sigma, k_rep, groupings, beta, delta, dist)
## Update mass parameter:
beta <- update_beta(beta, groupings, delta, dist, sigma)
## Update discount parameter (delta):
delta <- update_delta(groupings, beta, delta, dist, sigma)
# Update gamma/alpha:
# Combine counts
n_curr <- combine_counts(groupings, n_i)
# Update gamma:
gamma <- exp(gamma_update(z, z_1m, ncol(n_i), n_i = n_curr, nrow(n_curr) , log(gamma), g.a, g.b))
# Update z:
z <- update_z(z,
z_1m,
ncol(n_i),
n_i = n_curr,
nrow(n_curr),
log(gamma),
unique(prior.alpha))
z_1m <- sapply(z, log1mexp)
# Translate to alpha:
alpha <- exp(alpha_map(z, z_1m))
# Thin:
if (b %% thin == 0) {
alpha_sav[b / thin, ] <- alpha[subset]
groupings_sav[b / thin, ] <- groupings
gamma_sav[b / thin] <- gamma
beta_sav[b / thin] <- beta
delta_sav[b / thin] <- delta
for (g in unique(groupings)) {
ind <- which(groupings == g)
theta_sav[b / thin, ind, ] <- matrix(
rep(
LaplacesDemon::rdirichlet(1, n_curr[g, ] + alpha * gamma)[1, subset],
length(ind)
),
nrow = length(ind),
byrow = T
)
}
}
}
