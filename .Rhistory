p_use <- numeric(K)
p_use[i] <- j
for (g in 1:length(ids)) {
p_use[res[[g]]] <- g
}
if (j != length(ids) + 1) {
n_use[j, ] <- n_use[j, ] + n_i[i, ]
} else{
n_use <- rbind(n_use, n_i[i, ])
}
log_lik[j] <- log_full_joint(n_use, alpha, gamma, prior.alpha, g.a, g.b)
log_prior[j] <- log_epa_prior(p_use, beta, delta, dist, sigma)
}
log_lik <- log_lik - max(log_lik)
log_prior <- log_prior - max(log_prior)
log_probs <- log_lik + log_prior
log_probs <- log_probs - max(log_probs)
probs <- exp(log_probs) / sum(exp(log_probs))
n_g <- sample(1:(length(ids) + 1), 1, prob = probs)
alloc.new <- numeric(K)
for (j in 1:length(ids)) {
alloc.new[res[[j]]] <- j
}
alloc.new[i] <- n_g
groupings <- alloc.new
}
groupings
}
# Update permutation:
update_sigma <- function(sigma, k_rep, grouping, beta, delta, dist) {
sigma_prop <- sigma
ind <- sample(1:length(sigma), k_rep)
sigma_prop[ind] <- sample(sigma_prop[ind])
# accept/reject:
a <- log_epa_prior(grouping, beta, delta, dist, sigma_prop) -
log_epa_prior(grouping, beta, delta, dist, sigma)
if (a > log(runif(1))){
prop <- sigma_prop
} else{
prop <- sigma
}
prop
}
# Update mass parameter (beta):
update_beta <- function(beta, grouping, delta, dist, sigma) {
beta_prop <- beta + rnorm(1, mean = 0, sd = .5)
a <- log_epa_prior(grouping, beta_prop, delta, dist, sigma) + dgamma(beta_prop, 3, 5, log = T) -
log_epa_prior(grouping, beta, delta, dist, sigma) - dgamma(beta, 3, 5, log = T)
if (a > log(runif(1))) {
prop <- beta_prop
} else{
prop <- beta
}
prop
}
# Update discount parameter (delta):
update_delta <- function(grouping, beta, delta, dist, sigma) {
# Stepping in Slice Sampler:
L <- 0
U <- 1
f_x <- exp(log_epa_prior(grouping, beta, delta, dist, sigma) + log_delta_prior(delta))
y <- runif(1, 0, f_x)
x <- runif(1, L, U)
while (log(y) > log_epa_prior(grouping, beta, x, dist, sigma) + log_delta_prior(x)) {
if (x < delta) {
L = x
} else{
U = x
}
x <- runif(1, L, U)
}
x
}
# Function to run MCMC:(methods = aao or seq)
epa_mcmc <- function(N_i,
B = 10000,
thin = 1,
method = "aao",
prior.alpha,
g.a,
g.b,
dist) {
# Fix n_i:
non.na.ind <- !is.na(N_i[1, ])
J <- sum(non.na.ind)#ifelse(is.null(ncol(N_i)), length(N_i), ncol(N_i))
n_i <- N_i[, !is.na(N_i[1, ])]
if (is.null(nrow(n_i))) {
n_i <- array(n_i, dim = c(1, length(n_i)))
}
K <- ifelse(is.null(nrow(n_i)), 1, nrow(n_i))
# Set prior parameters:
prior.alpha <- rep(prior.alpha, ncol(n_i))
beta <- beta_sav <- .9
delta <- delta_sav <- 0.01
sigma <- 1:K
k_rep <- floor(K / 2)
## Get initial values for alpha and gamma
alpha <- array(NA, dim = c(1, ncol(n_i)))
alpha[1, ] <- rep(1 / ncol(n_i), ncol(n_i))
z <- alpha_to_z(log(alpha))
z_1m <- sapply(z, log1mexp)
gamma <- gamma_sav <- 5#rgamma(1, g.a, g.b)
tables <- matrix(c(1, 1), nrow = 2)
group_alloc <- 1
groupings_sav <- array(NA, dim = c(B, nrow(n_i)))
alpha_sav <- array(NA, dim = c(B, ncol(n_i)))
theta_sav <- array(NA, dim = c(B, K, ncol(n_i)))
# Possible partitions:
if(K <= 13){
p <- salso::enumerate.partitions(K)
groupings <- p[sample(1:nrow(p), 1), ]
} else {
num_groups <- sample(1:K, 1)
groupings <- sample(1:num_groups, K, replace = TRUE)
}
# Reorder by counts:
max.col <- which.max(apply(n_i, 2, sum))
n_i <- n_i[ , c(c(1:length(n_i[1,]))[-max.col], max.col)]
if(max.col == 1){
subset <- c(length(alpha), max.col:(length(alpha) - 1))
} else if(max.col == length(alpha)){
subset <- 1:length(alpha)
}else{
subset <- c(1:(max.col - 1), length(alpha), max.col:(length(alpha) - 1))
}
# Run MCMC:
# prior probs of partitions:
# Run MCMC:
for (b in 2:(B * thin)) {
## Update groupings:
if (method == "aao") {
groupings <- update_groupings_aao(p,
beta,
delta,
dist,
sigma,
alpha,
gamma,
n_i,
prior.alpha,
g.a,
g.b,
K)
} else{
groupings <- update_groupings_seq(n_i,
groupings,
alpha,
gamma,
beta,
delta,
sigma,
dist,
prior.alpha,
g.a,
g.b,
K)
}
## Update permutation (sigma):
sigma <- update_sigma(sigma, k_rep, groupings, beta, delta, dist)
## Update mass parameter:
beta <- update_beta(beta, groupings, delta, dist, sigma)
## Update discount parameter (delta):
delta <- update_delta(groupings, beta, delta, dist, sigma)
# Update gamma/alpha:
# Combine counts
n_curr <- combine_counts(groupings, n_i)
# Update gamma:
gamma <- gamma_update(z, z_1m, ncol(n_i), n_i = n_curr, nrow(n_curr) , log(gamma), g.a, g.b)
# Update z:
z <- update_z(z,
z_1m,
ncol(n_i),
n_i = n_curr,
nrow(n_curr),
gamma,
unique(prior.alpha))
z_1m <- sapply(z, log1mexp)
# Translate to alpha:
alpha <- exp(alpha_map(z, z_1m))
# Thin:
if (b %% thin == 0) {
alpha_sav[b / thin, ] <- alpha[subset]
groupings_sav[b / thin, ] <- groupings
gamma_sav[b / thin] <- exp(gamma)
beta_sav[b / thin] <- beta
delta_sav[b / thin] <- delta
for (g in unique(groupings)) {
ind <- which(groupings == g)
theta_sav[b / thin, ind, ] <- matrix(
rep(
LaplacesDemon::rdirichlet(1, n_curr[g, ] + alpha * gamma)[1, subset],
length(ind)
),
nrow = length(ind),
byrow = T
)
}
}
}
J <- ifelse(is.null(ncol(N_i)), length(N_i), ncol(N_i))
alpha <- array(0, dim = c(B, J))
alpha[, non.na.ind] <- alpha_sav
theta <- array(0, dim = c(B, K, J))
theta[, , non.na.ind] <- theta_sav
return(
list(
groups = groupings_sav,
alpha = alpha,
gamma = gamma_sav,
theta = theta,
beta = beta_sav,
delta = delta_sav
)
)
}
## Function for HAMC MCMC:
hamc_mcmc <- function(n_i, K, g.a, g.b, prior.alpha, B) {
J <- sum(!is.na(n_i[1, ]))
# Fix dimension of n_i if only one group:
if (is.null(dim(n_i))) {
n_i <- matrix(n_i, nrow = 1)
}
# initialize gamma and alpha (log scale)
g <- c(log(1))
alpha <- array(NA, dim = c(B + 500, J))
theta <- array(0, dim = c(B + 500, K, length(n_i[1, ])))
alpha[1, ] <- log(rep(1 / J, J))
for (k in 1:K) {
theta[1, k, !is.na(n_i[k, ])] <- LaplacesDemon::rdirichlet(1, exp(g[1] + alpha[1, ]) + n_i[k, ][!is.na(n_i[k, ])])
}
z <- z_1m <- psi <- array(NA, dim = c(B + 500, J - 1))
z[1, ] <- alpha_to_z(alpha[1, ])
psi[1, ] <- pbeta(exp(z[1, ]), .5, .5)
z_1m[1, ] <- sapply(z[1, ], log1mexp)
# Reorder by counts:
max.col <- which.max(apply(n_i, 2, sum))
n_i <- n_i[ , c(c(1:length(n_i[1,]))[-max.col], max.col)]
if(max.col == 1){
subset <- c(length(alpha[1,]), max.col:(length(alpha[1,]) - 1))
} else{
subset <- c(1:(max.col - 1), length(alpha[1,]), max.col:(length(alpha[1,]) - 1))
}
# Start MCMC:
for (iter in 2:(B + 500)) {
# Update Gamma:
# Slice:
g[iter] <- gamma_update(z[iter - 1, ], z_1m[iter - 1, ], J, n_i
, K, g[iter - 1], g.a, g.b)
# Update alpha:
## Map to z(beta) variables:
## Update z values (does accept/reject with slice sampler):
z[iter, ] <- update_z(z[iter - 1, ], z_1m[iter - 1, ], J, n_i = n_i
, K, g[iter], prior.alpha)
psi[iter, ] <- pbeta(exp(z[iter, ]), .5, .5)
z_1m[iter, ] <- sapply(z[iter, ], log1mexp)
alpha[iter, ] <- alpha_map(z[iter, ], z_1m[iter, ])
for (k in 1:K) {
theta[iter, k, !is.na(n_i[k, subset])] <- LaplacesDemon::rdirichlet(1, exp(g[iter] + alpha[iter, subset]) + n_i[k, subset][!is.na(n_i[k, subset])])
}
}
# Save row draws:
alpha_draws <- array(0, dim = c(B, length(n_i[k, ])))
alpha_draws[, !is.na(n_i[1, ])] <- exp(alpha[-c(1:500), subset])
gamma_draws <- exp(g[-c(1:500)])
theta_draws <- theta[-c(1:500), , ]
#print(i)
return(list(
alpha = alpha_draws,
gamma = gamma_draws,
theta = theta_draws
))
}
#' HAMC-EPA model
#'
#' @description
#' This function fits an indpendent HAMC-EPA model on each row of the transition matrix and outputs posterior draws of clustering, alpha, gamma, and the transition probabilities.
#'
#'
#' @param N A three dimensional array of counts (KxIxJ) where K is the number of subgroups, I is the number of transitory states, J is the total number of states. Include NA's in matrix for impossible transitions.
#' @param method The MCMC approach to obtaining posterior draws of the random clusters. Options "aao" or "seq". "aao" is an "all-at-once" approach in that it evaluates the posterior probability of each possible partition. "seq" does a sequential allocation of clustering given the previous clustering draw. When there are a small number of subgroups "aao" may be prefered however as the number of subgroups increases the computation time increases dramatically.
#' @param B Number of desired posterior estimates
#' @param thin Thinning of MCMC draws, i.e. thin = 5, means every 5th draw will be returned.
#' @param prior.alpha The value to be included in the prior for the Dirichlet on alpha, will be uniform. Default is 1/(# of possible transition for each row).
#' @param g.a The prior shape parameter of the gamma distribution for the gamma parameter. Default uses a mean of 20 and standard deviation of 18.
#' @param g.b The prior rate parameter of the gamma distribution for the gamma parameter. Default uses a mean of 20 and standard deviation of 18.
#' @param dist A KxK symmetric matrix that includes the prior information on the distance between subgroups. Defaults to each group is sequentially one from the next in line.
#' @param MCMC.cores The number of cores desired to use to run, if greater than 1 parallel processing will be used. Default is 1 (no parallelization).
#' @param burnin The number of burn in iterations to be removed from the posterior draws. Default is 500.
#'
#' @return A list with the following:
#'  \itemize{
#'    \item groups - The posterior draws of the clustering from each MCMC draw. (BxIxK)
#'    \item alpha - Posterior draws of the alpha parameter. (BxIxJ)
#'    \item gamma - Posterior draws of the gamma parameter. (BxI)
#'    \item theta - Posterior draws of the transition probabilities. (BxKxIxJ)
#'  }
#' @export
#' @examples
#'
# Write function:
epa_hamc <- function(N,
method = "aao",
B = 10000,
thin = 1,
prior.alpha = NULL,
g.a = NULL,
g.b = NULL,
dist = NULL,
MCMC.cores = 1,
burnin = 500) {
# Check compatability of N:
if (!is.array(N)) {
stop(paste("N must be an array."))
}
if (length(dim(N)) < 3) {
stop(paste("N must be a three dimensional array."))
}
# Check method argument:
if (!(method %in% c("aao", "seq"))) {
stop(paste("Invalid method argument"))
}
# Check B, thin, prior.alpha, g.a, g.b are numeric if input is supplied:
if (!is.numeric(B)) {
stop(paste("B must be numeric"))
}
if (!is.numeric(thin)) {
stop(paste("thin must be numeric"))
}
if (!is.null(g.a) & !is.numeric(g.a)) {
stop(paste("g.a must be numeric"))
}
if (!is.null(g.b) & !is.numeric(g.b)) {
stop(paste("g.b must be numeric"))
}
# Make sure prior parameters are positive:
if (!is.null(prior.alpha)) {
if (prior.alpha <= 0) {
stop(paste("prior.alpha must be positive"))
}
}
if (is.null(prior.alpha)) {
prior.alpha <- c()
for (i in 1:dim(N)[2]) {
prior.alpha[i] <- 1 / sum(!is.na(N[1, i, ]))
}
}
if (!is.null(g.a)) {
if (g.a <= 0) {
stop(paste("g.a must be positive"))
}
}
if (!is.null(g.b)) {
if (g.b <= 0) {
stop(paste("g.b must be positive"))
}
}
# Check distance matrix and correct dimensions:
K <- dim(N)[1]
if (!is.null(dist)) {
if (!is.matrix(dist)) {
stop("dist must be a matrix.")
}
if (dim(dist)[1] != K) {
stop("Wrong dimensions for distance matrix.")
}
}
# Check if method and number of groups match:
if(K > 13 & method == "aao"){
stop("K is greater than 13 and method must be sequential.")
}
# Check dimensions
if (is.null(dist)) {
dist <- matrix(1, nrow = K, ncol = K)
for (k in 1:K) {
dist[c(1:K)[-k], k] <- abs(c(1:K)[-k] - k)
}
dist[K, K] <- 1
# Convert to similarity matrix for EPA model:
dist <- dist ^ (-.5)
} else {
# Convert to similarity matrix for EPA model:
dist <- dist ^ (-.5)
}
## Populate g.a and g.b if missing:
if (is.null(g.a) | is.null(g.b)) {
mu <- 20
sd <- 18
g.b <- mu / sd ^ 2
g.a <- mu * g.b
}
# Make the data into a list:
count.list <- list()
for (i in 1:dim(N)[2]) {
count.list[[i]] <- N[, i, ]
}
## Fit model:
## Check configuration of prior.alpha if it varies from row to row:
if (length(unique(prior.alpha)) == 1) {
prior.alpha <- unique(prior.alpha)
fit <- parallel::mclapply(count.list,
\(x) epa_mcmc(x, B + burnin, thin, method, prior.alpha, g.a, g.b, dist),
mc.cores = MCMC.cores)
} else{
for (i in 1:dim(N)[2]) {
count.list[[i]] <- cbind(count.list[[i]], prior.alpha[i])
}
fit <- parallel::mclapply(count.list,
\(x) epa_mcmc(x[, 1:(ncol(x) - 1)], B + burnin, thin, method, x[1, ncol(x)], g.a, g.b, dist),
mc.cores = MCMC.cores)
}
## Create output list options:
I <- dim(N)[2]
J <- dim(N)[3]
groupings <- array(NA, dim = c(B, I, K))
alpha <- array(0, dim = c(B, I, J))
gamma <- array(0, dim = c(B, I))
theta <- array(0, dim = c(B, K, I, J))
for (i in 1:I) {
groupings[, i, ] <- fit[[i]][[1]][-c(1:burnin), ]
alpha[, i, ] <- fit[[i]][[2]][-c(1:burnin), ]
gamma[, i] <- fit[[i]][[3]][-c(1:burnin)]
theta[, , i, ] <- fit[[i]][[4]][-c(1:burnin), , ]
}
output <- list(
groups = groupings,
alpha = alpha,
gamma = gamma,
theta = theta
)
return(output)
}
library(amcModels)
fit_epa <- epa_hamc(N, method = "seq", thin = 5, MCMC.cores = 1)
P1 <- P2 <- matrix(c(.3, .2, .25, .15, .1,
.1, .3, .4, .1, .1,
.05, .5, .2, .1, .15), nrow = 3, ncol = 5,
byrow = TRUE)
P3 <- matrix(c(.1, .3, .3, .15, .15,
.1, .3, .1, .1, .4,
.5, .05, .1, .05, .3), nrow = 3, ncol = 5,
byrow = TRUE)
P4 <- matrix(c(.15, .25, .3, .2, .1,
.15, .2, .45, .1, .1,
.4, .05, .1, .1, .35), nrow = 3, ncol = 5,
byrow = TRUE)
P5 <- matrix(c(.1, .3, .3, .15, .15,
.3, .3, .25, .1, .05,
.05, .3, .1, .05, .5), nrow = 3, ncol = 5,
byrow = TRUE)
P6 <- matrix(c(.6, .1, .1, .1, .1,
.3, .4, .1, .1, .1,
.05, .3, .15, .05, .45), nrow = 3, ncol = 5,
byrow = TRUE)
n <- 100
## Simulate data starting in state 1:
data_1_1 <- absmarkovchain(1, P1, 100)
data_2_1 <- absmarkovchain(1, P2, 100)
data_3_1 <- absmarkovchain(1, P3, 100)
data_4_1 <- absmarkovchain(1, P4, 100)
data_5_1 <- absmarkovchain(1, P5, 100)
data_6_1 <- absmarkovchain(1, P6, 100)
## Simulate data starting in state 2:
data_1_2 <- absmarkovchain(2, P1, 100)
data_2_2 <- absmarkovchain(2, P2, 100)
data_3_2 <- absmarkovchain(2, P3, 100)
data_4_2 <- absmarkovchain(2, P4, 100)
data_5_2 <- absmarkovchain(2, P5, 100)
data_6_2 <- absmarkovchain(2, P6, 100)
## Simulate data starting in state 3:
data_1_3 <- absmarkovchain(3, P1, 100)
data_2_3 <- absmarkovchain(3, P2, 100)
data_3_3 <- absmarkovchain(3, P3, 100)
data_4_3 <- absmarkovchain(3, P4, 100)
data_5_3 <- absmarkovchain(3, P5, 100)
data_6_3 <- absmarkovchain(3, P6, 100)
N <- array(0, dim = c(6, 3, 5))
## Function to apply to each sequence:
make_counts <- function(seq, N_group){
for(x in 2:length(seq)){
row.ref <- seq[x - 1]
col.ref <- seq[x]
N_group[row.ref, col.ref] <- N_group[row.ref, col.ref] + 1
}
return(N_group)
}
for(i in 1:100){
## Group 1:
N[1, , ] <- make_counts(data_1_1[[i]], N[1, , ])
N[1, , ] <- make_counts(data_1_2[[i]], N[1, , ])
N[1, , ] <- make_counts(data_1_3[[i]], N[1, , ])
## Group 2:
N[2, , ] <- make_counts(data_2_1[[i]], N[2, , ])
N[2, , ] <- make_counts(data_2_2[[i]], N[2, , ])
N[2, , ] <- make_counts(data_2_3[[i]], N[2, , ])
## Group 3:
N[3, , ] <- make_counts(data_3_1[[i]], N[3, , ])
N[3, , ] <- make_counts(data_3_2[[i]], N[3, , ])
N[3, , ] <- make_counts(data_3_3[[i]], N[3, , ])
## Group 4:
N[4, , ] <- make_counts(data_4_1[[i]], N[4, , ])
N[4, , ] <- make_counts(data_4_2[[i]], N[4, , ])
N[4, , ] <- make_counts(data_4_3[[i]], N[4, , ])
## Group 5:
N[5, , ] <- make_counts(data_5_1[[i]], N[5, , ])
N[5, , ] <- make_counts(data_5_2[[i]], N[5, , ])
N[5, , ] <- make_counts(data_5_3[[i]], N[5, , ])
## Group 6:
N[6, , ] <- make_counts(data_6_1[[i]], N[6, , ])
N[6, , ] <- make_counts(data_6_2[[i]], N[6, , ])
N[6, , ] <- make_counts(data_6_3[[i]], N[6, , ])
}
fit_epa <- epa_hamc(N, method = "seq", thin = 5, MCMC.cores = 1)
